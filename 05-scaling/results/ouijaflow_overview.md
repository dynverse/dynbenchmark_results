# ouijaflow
![Overview](ouijaflow.png)

## ERROR STATUS METHOD_ERROR

### ERROR CLUSTER METHOD_ERROR -- 1
![Cluster plot](error_class_plots/ouijaflow_method_error_1.png)

 * Number of instances: 333
 * Dataset ids: scaling_0298, scaling_0337, scaling_0416, scaling_0417, scaling_0419, scaling_0475, scaling_0476, scaling_0514, scaling_0531, scaling_0536, scaling_0566, scaling_0582, scaling_0591, scaling_0613, scaling_0616, scaling_0617, scaling_0618, scaling_0623, scaling_0664, scaling_0668, scaling_0678, scaling_0684, scaling_0698, scaling_0701, scaling_0715, scaling_0718, scaling_0724, scaling_0726, scaling_0728, scaling_0731, scaling_0750, scaling_0763, scaling_0764, scaling_0766, scaling_0782, scaling_0784, scaling_0800, scaling_0803, scaling_0806, scaling_0817, scaling_0820, scaling_0821, scaling_0823, scaling_0824, scaling_0825, scaling_0832, scaling_0836, scaling_0837, scaling_0841, scaling_0853, scaling_0854, scaling_0855, scaling_0856, scaling_0857, scaling_0866, scaling_0867, scaling_0868, scaling_0869, scaling_0870, scaling_0876, scaling_0877, scaling_0878, scaling_0879, scaling_0881, scaling_0887, scaling_0888, scaling_0889, scaling_0891, scaling_0898, scaling_0899, scaling_0902, scaling_0910, scaling_0912, scaling_0918, scaling_0919, scaling_0928, scaling_0936, scaling_0942, scaling_0951, scaling_0957, scaling_0961, scaling_0963, scaling_0964, scaling_0965, scaling_0968, scaling_0969, scaling_0978, scaling_0980, scaling_0981, scaling_0982, scaling_0989, scaling_0993, scaling_0994, scaling_0995, scaling_1008, scaling_1009, scaling_1010, scaling_1022, scaling_1023, scaling_1026, scaling_1036, scaling_1039, scaling_1042, scaling_1048, scaling_1049, scaling_1050, scaling_1051, scaling_1052, scaling_1053, scaling_1055, scaling_1066, scaling_1067, scaling_1068, scaling_1069, scaling_1070, scaling_1071, scaling_1072, scaling_1073, scaling_1074, scaling_1082, scaling_1084, scaling_1085, scaling_1086, scaling_1088, scaling_1089, scaling_1090, scaling_1091, scaling_1093, scaling_1094, scaling_1097, scaling_1103, scaling_1106, scaling_1107, scaling_1108, scaling_1109, scaling_1110, scaling_1112, scaling_1125, scaling_1126, scaling_1129, scaling_1130, scaling_1133, scaling_1145, scaling_1146, scaling_1147, scaling_1149, scaling_1150, scaling_1151, scaling_1152, scaling_1153, scaling_1154, scaling_1157, scaling_1158, scaling_1161, scaling_1166, scaling_1167, scaling_1168, scaling_1172, scaling_1179, scaling_1180, scaling_1181, scaling_1182, scaling_1183, scaling_1184, scaling_1189, scaling_1190, scaling_1196, scaling_1197, scaling_1198, scaling_1199, scaling_1202, scaling_1212, scaling_1213, scaling_1214, scaling_1215, scaling_1216, scaling_1217, scaling_1218, scaling_1225, scaling_1227, scaling_1228, scaling_1229, scaling_1231, scaling_1232, scaling_1233, scaling_1242, scaling_1243, scaling_1244, scaling_1245, scaling_1249, scaling_1250, scaling_1253, scaling_1254, scaling_1257, scaling_1258, scaling_1261, scaling_1262, scaling_1265, scaling_1266, scaling_1267, scaling_1268, scaling_1270, scaling_1272, scaling_1273, scaling_1274, scaling_1276, scaling_1277, scaling_1278, scaling_1279, scaling_1280, scaling_1282, scaling_1283, scaling_1285, scaling_1289, scaling_1293, scaling_1294, scaling_1295, scaling_1296, scaling_1297, scaling_1298, scaling_1299, scaling_1300, scaling_1302, scaling_1304, scaling_1315, scaling_1316, scaling_1317, scaling_1318, scaling_1319, scaling_1320, scaling_1321, scaling_1322, scaling_1323, scaling_1324, scaling_1328, scaling_1331, scaling_1334, scaling_1335, scaling_1336, scaling_1337, scaling_1338, scaling_1339, scaling_1340, scaling_1341, scaling_1342, scaling_1344, scaling_1349, scaling_1350, scaling_1355, scaling_1357, scaling_1358, scaling_1359, scaling_1361, scaling_1362, scaling_1363, scaling_1364, scaling_1365, scaling_1374, scaling_1375, scaling_1376, scaling_1377, scaling_1378, scaling_1379, scaling_1380, scaling_1381, scaling_1382, scaling_1383, scaling_1384, scaling_1386, scaling_1391, scaling_1392, scaling_1393, scaling_1394, scaling_1395, scaling_1398, scaling_1402, scaling_1403, scaling_1404, scaling_1405, scaling_1406, scaling_1407, scaling_1412, scaling_1416, scaling_1417, scaling_1418, scaling_1419, scaling_1424, scaling_1425, scaling_1427, scaling_1428, scaling_1429, scaling_1430, scaling_1438, scaling_1439, scaling_1440, scaling_1441, scaling_1442, scaling_1443, scaling_1444, scaling_1449, scaling_1450, scaling_1451, scaling_1452, scaling_1453, scaling_1454, scaling_1455, scaling_1456, scaling_1463, scaling_1464, scaling_1465, scaling_1466, scaling_1467, scaling_1469, scaling_1471, scaling_1472, scaling_1473, scaling_1474, scaling_1475, scaling_1476, scaling_1477, scaling_1478, scaling_1479, scaling_1480, scaling_1484, scaling_1485, scaling_1486, scaling_1487, scaling_1488, scaling_1490, scaling_1493, scaling_1498, scaling_1499, scaling_1500

Last 10 lines of scaling_0298:
```
  /group/irc/shared/dynverse/dynbenchmark/derived/singularity_images/dynverse/ti_ouijaflow.simg
   1/1000 [  0%]                                ETA: 2984s | Loss: 37241.809  10/1000 [  1%]                                ETA: 299s | Loss: 33574.777   20/1000 [  2%]                                ETA: 150s | Loss: 26042.598  30/1000 [  3%]                                ETA: 100s | Loss: 20708.703  40/1000 [  4%] █                              ETA: 75s | Loss: 23336.438   50/1000 [  5%] █                              ETA: 60s | Loss: nan        60/1000 [  6%] █                              ETA: 50s | Loss: nan  70/1000 [  7%] ██                             ETA: 43s | Loss: nan  80/1000 [  8%] ██                             ETA: 38s | Loss: nan  90/1000 [  9%] ██                             ETA: 34s | Loss: nan 100/1000 [ 10%] ███                            ETA: 30s | Loss: nan 110/1000 [ 11%] ███                            ETA: 27s | Loss: nan 120/1000 [ 12%] ███                            ETA: 25s | Loss: nan 130/1000 [ 13%] ███                            ETA: 23s | Loss: nan 140/1000 [ 14%] ████                           ETA: 22s | Loss: nan 150/1000 [ 15%] ████                           ETA: 20s | Loss: nan 160/1000 [ 16%] ████                           ETA: 19s | Loss: nan 170/1000 [ 17%] █████                          ETA: 18s | Loss: nan 180/1000 [ 18%] █████                          ETA: 17s | Loss: nan 190/1000 [ 19%] █████                          ETA: 16s | Loss: nan 200/1000 [ 20%] ██████                         ETA: 15s | Loss: nan 210/1000 [ 21%] ██████                         ETA: 15s | Loss: nan 220/1000 [ 22%] ██████                         ETA: 14s | Loss: nan 230/1000 [ 23%] ██████                         ETA: 13s | Loss: nan 240/1000 [ 24%] ███████                        ETA: 13s | Loss: nan 250/1000 [ 25%] ███████                        ETA: 12s | Loss: nan 260/1000 [ 26%] ███████                        ETA: 12s | Loss: nan 270/1000 [ 27%] ████████                       ETA: 11s | Loss: nan 280/1000 [ 28%] ████████                       ETA: 11s | Loss: nan 290/1000 [ 28%] ████████                       ETA: 10s | Loss: nan 300/1000 [ 30%] █████████                      ETA: 10s | Loss: nan 310/1000 [ 31%] █████████                      ETA: 10s | Loss: nan 320/1000 [ 32%] █████████                      ETA: 9s | Loss: nan  330/1000 [ 33%] █████████                      ETA: 9s | Loss: nan 340/1000 [ 34%] ██████████                     ETA: 9s | Loss: nan 350/1000 [ 35%] ██████████                     ETA: 8s | Loss: nan 360/1000 [ 36%] ██████████                     ETA: 8s | Loss: nan 370/1000 [ 37%] ███████████                    ETA: 8s | Loss: nan 380/1000 [ 38%] ███████████                    ETA: 8s | Loss: nan 390/1000 [ 39%] ███████████                    ETA: 7s | Loss: nan 400/1000 [ 40%] ████████████                   ETA: 7s | Loss: nan 410/1000 [ 41%] ████████████                   ETA: 7s | Loss: nan 420/1000 [ 42%] ████████████                   ETA: 7s | Loss: nan 430/1000 [ 43%] ████████████                   ETA: 6s | Loss: nan 440/1000 [ 44%] █████████████                  ETA: 6s | Loss: nan 450/1000 [ 45%] █████████████                  ETA: 6s | Loss: nan 460/1000 [ 46%] █████████████                  ETA: 6s | Loss: nan 470/1000 [ 47%] ██████████████                 ETA: 6s | Loss: nan 480/1000 [ 48%] ██████████████                 ETA: 5s | Loss: nan 490/1000 [ 49%] ██████████████                 ETA: 5s | Loss: nan 500/1000 [ 50%] ███████████████                ETA: 5s | Loss: nan 510/1000 [ 51%] ███████████████                ETA: 5s | Loss: nan 520/1000 [ 52%] ███████████████                ETA: 5s | Loss: nan 530/1000 [ 53%] ███████████████                ETA: 5s | Loss: nan 540/1000 [ 54%] ████████████████               ETA: 4s | Loss: nan 550/1000 [ 55%] ████████████████               ETA: 4s | Loss: nan 560/1000 [ 56%] ████████████████               ETA: 4s | Loss: nan 570/1000 [ 56%] █████████████████              ETA: 4s | Loss: nan 580/1000 [ 57%] █████████████████              ETA: 4s | Loss: nan 590/1000 [ 59%] █████████████████              ETA: 4s | Loss: nan 600/1000 [ 60%] ██████████████████             ETA: 3s | Loss: nan 610/1000 [ 61%] ██████████████████             ETA: 3s | Loss: nan 620/1000 [ 62%] ██████████████████             ETA: 3s | Loss: nan 630/1000 [ 63%] ██████████████████             ETA: 3s | Loss: nan 640/1000 [ 64%] ███████████████████            ETA: 3s | Loss: nan 650/1000 [ 65%] ███████████████████            ETA: 3s | Loss: nan 660/1000 [ 66%] ███████████████████            ETA: 3s | Loss: nan 670/1000 [ 67%] ████████████████████           ETA: 3s | Loss: nan 680/1000 [ 68%] ████████████████████           ETA: 2s | Loss: nan 690/1000 [ 69%] ████████████████████           ETA: 2s | Loss: nan 700/1000 [ 70%] █████████████████████          ETA: 2s | Loss: nan 710/1000 [ 71%] █████████████████████          ETA: 2s | Loss: nan 720/1000 [ 72%] █████████████████████          ETA: 2s | Loss: nan 730/1000 [ 73%] █████████████████████          ETA: 2s | Loss: nan 740/1000 [ 74%] ██████████████████████         ETA: 2s | Loss: nan 750/1000 [ 75%] ██████████████████████         ETA: 2s | Loss: nan 760/1000 [ 76%] ██████████████████████         ETA: 2s | Loss: nan 770/1000 [ 77%] ███████████████████████        ETA: 2s | Loss: nan 780/1000 [ 78%] ███████████████████████        ETA: 1s | Loss: nan 790/1000 [ 79%] ███████████████████████        ETA: 1s | Loss: nan 800/1000 [ 80%] ████████████████████████       ETA: 1s | Loss: nan 810/1000 [ 81%] ████████████████████████       ETA: 1s | Loss: nan 820/1000 [ 82%] ████████████████████████       ETA: 1s | Loss: nan 830/1000 [ 83%] ████████████████████████       ETA: 1s | Loss: nan 840/1000 [ 84%] █████████████████████████      ETA: 1s | Loss: nan 850/1000 [ 85%] █████████████████████████      ETA: 1s | Loss: nan 860/1000 [ 86%] █████████████████████████      ETA: 1s | Loss: nan 870/1000 [ 87%] ██████████████████████████     ETA: 1s | Loss: nan 880/1000 [ 88%] ██████████████████████████     ETA: 0s | Loss: nan 890/1000 [ 89%] ██████████████████████████     ETA: 0s | Loss: nan 900/1000 [ 90%] ███████████████████████████    ETA: 0s | Loss: nan 910/1000 [ 91%] ███████████████████████████    ETA: 0s | Loss: nan 920/1000 [ 92%] ███████████████████████████    ETA: 0s | Loss: nan 930/1000 [ 93%] ███████████████████████████    ETA: 0s | Loss: nan 940/1000 [ 94%] ████████████████████████████   ETA: 0s | Loss: nan 950/1000 [ 95%] ████████████████████████████   ETA: 0s | Loss: nan 960/1000 [ 96%] ████████████████████████████   ETA: 0s | Loss: nan 970/1000 [ 97%] █████████████████████████████  ETA: 0s | Loss: nan 980/1000 [ 98%] █████████████████████████████  ETA: 0s | Loss: nan 990/1000 [ 99%] █████████████████████████████  ETA: 0s | Loss: nan1000/1000 [100%] ██████████████████████████████ Elapsed: 7s | Loss: nan
/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  not np.issubdtype(value.dtype, np.float) and \
output saved in /data/tmp//Rtmp9OeXJY/filed4c6b4ad73c/ti/output: 
	cell_ids.csv
	pseudotime.csv
	timings.json
all(pg_check >= 0 & pg_check < (1 + 1e-06)) isn't true.
Sum of progressions per cell_id should be exactly one
```

### ERROR CLUSTER METHOD_ERROR -- 2
![Cluster plot](error_class_plots/ouijaflow_method_error_2.png)

 * Number of instances: 25
 * Dataset ids: scaling_2087, scaling_2116, scaling_2122, scaling_2128, scaling_2134, scaling_2140, scaling_2148, scaling_2180, scaling_2212, scaling_2227, scaling_2230, scaling_2248, scaling_2249, scaling_2250, scaling_2251, scaling_2269, scaling_2272, scaling_2293, scaling_2294, scaling_2295, scaling_2311, scaling_2313, scaling_2314, scaling_2315, scaling_2316

Last 10 lines of scaling_2087:
```
Input saved to /data/tmp//RtmpIfpgMq/file1909b149d2fd1/ti/input: 
	expression.csv
	params.json
Running /bin/singularity run --pwd /ti/workspace -B \
  '/data/tmp//RtmpIfpgMq/file1909b149d2fd1/ti:/ti,/data/tmp//RtmpIfpgMq/file1909b2f55437c/tmp:/tmp2' \
  /group/irc/shared/dynverse/dynbenchmark/derived/singularity_images/dynverse/ti_ouijaflow.simg
```

## ERROR STATUS MEMORY_LIMIT

### ERROR CLUSTER MEMORY_LIMIT -- 1
![Cluster plot](error_class_plots/ouijaflow_memory_limit_1.png)

 * Number of instances: 87
 * Dataset ids: scaling_1501, scaling_1506, scaling_1513, scaling_1528, scaling_1530, scaling_1532, scaling_1548, scaling_1560, scaling_1568, scaling_1576, scaling_1577, scaling_1586, scaling_1591, scaling_1602, scaling_1605, scaling_1618, scaling_1619, scaling_1630, scaling_1633, scaling_1636, scaling_1638, scaling_1646, scaling_1650, scaling_1656, scaling_1657, scaling_1661, scaling_1664, scaling_1665, scaling_1670, scaling_1673, scaling_1674, scaling_1676, scaling_1678, scaling_1679, scaling_1680, scaling_1684, scaling_1687, scaling_1690, scaling_1696, scaling_1697, scaling_1709, scaling_1722, scaling_1723, scaling_1724, scaling_1726, scaling_1730, scaling_1732, scaling_1734, scaling_1748, scaling_1751, scaling_1753, scaling_1764, scaling_1765, scaling_1769, scaling_1770, scaling_1783, scaling_1789, scaling_1791, scaling_1792, scaling_1812, scaling_1817, scaling_1821, scaling_1824, scaling_1829, scaling_1830, scaling_1839, scaling_1842, scaling_1848, scaling_1852, scaling_1855, scaling_1859, scaling_1873, scaling_1878, scaling_1885, scaling_1890, scaling_1892, scaling_1900, scaling_1905, scaling_1906, scaling_1916, scaling_1936, scaling_1958, scaling_1994, scaling_1998, scaling_2002, scaling_2074, scaling_2089

Last 10 lines of scaling_1501:
```
    "Pack", values=values, axis=axis, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2,63,100000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/stack = Pack[N=2, T=DT_FLOAT, axis=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/LogSigmoid_1, inference/sample/DropoutNormal_1/log_prob/add_2)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 2
![Cluster plot](error_class_plots/ouijaflow_memory_limit_2.png)

 * Number of instances: 101
 * Dataset ids: scaling_1502, scaling_1503, scaling_1504, scaling_1505, scaling_1507, scaling_1508, scaling_1512, scaling_1517, scaling_1519, scaling_1520, scaling_1521, scaling_1524, scaling_1525, scaling_1526, scaling_1529, scaling_1533, scaling_1534, scaling_1536, scaling_1537, scaling_1539, scaling_1540, scaling_1541, scaling_1544, scaling_1545, scaling_1546, scaling_1547, scaling_1549, scaling_1553, scaling_1556, scaling_1557, scaling_1558, scaling_1561, scaling_1562, scaling_1564, scaling_1565, scaling_1567, scaling_1574, scaling_1575, scaling_1578, scaling_1579, scaling_1584, scaling_1585, scaling_1589, scaling_1590, scaling_1592, scaling_1593, scaling_1594, scaling_1595, scaling_1596, scaling_1598, scaling_1599, scaling_1604, scaling_1609, scaling_1610, scaling_1611, scaling_1613, scaling_1615, scaling_1620, scaling_1621, scaling_1623, scaling_1625, scaling_1637, scaling_1639, scaling_1643, scaling_1663, scaling_1669, scaling_1671, scaling_1682, scaling_1685, scaling_1689, scaling_1692, scaling_1694, scaling_1704, scaling_1705, scaling_1708, scaling_1712, scaling_1727, scaling_1731, scaling_1738, scaling_1750, scaling_1760, scaling_1774, scaling_1779, scaling_1804, scaling_1814, scaling_1822, scaling_1825, scaling_1844, scaling_1871, scaling_1875, scaling_1879, scaling_1893, scaling_1895, scaling_1922, scaling_1970, scaling_1973, scaling_1980, scaling_1993, scaling_2019, scaling_2027, scaling_2106

Last 10 lines of scaling_1502:
```
    reduction_indices=reduction_indices))
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 432, in new_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1373, in reduce_sum
    name=name))
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 4864, in _sum
    name=name)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2,158,39811] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum_grad/Tile = Tile[T=DT_FLOAT, Tmultiples=DT_INT32, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum_grad/Reshape, gradients/inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum_grad/floordiv)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 3
![Cluster plot](error_class_plots/ouijaflow_memory_limit_3.png)

 * Number of instances: 36
 * Dataset ids: scaling_1509, scaling_1642, scaling_1672, scaling_1681, scaling_1695, scaling_1728, scaling_1747, scaling_1794, scaling_1795, scaling_1803, scaling_1806, scaling_1809, scaling_1832, scaling_1857, scaling_1863, scaling_1874, scaling_1897, scaling_1909, scaling_1912, scaling_1913, scaling_1917, scaling_1938, scaling_1960, scaling_1972, scaling_1978, scaling_2017, scaling_2040, scaling_2103, scaling_2120, scaling_2132, scaling_2137, scaling_2138, scaling_2174, scaling_2175, scaling_2177, scaling_2205

Last 10 lines of scaling_1509:
```
    return 0.5 * math.log(2. * math.pi) + math_ops.log(self.scale)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 2326, in log
    "Log", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[631,10000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/Log_grad/Reciprocal = Reciprocal[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/Normal/scale, ^gradients/inference/sample/DropoutNormal_1/log_prob/add_1_grad/Reshape_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 4
![Cluster plot](error_class_plots/ouijaflow_memory_limit_4.png)

 * Number of instances: 50
 * Dataset ids: scaling_1510, scaling_1511, scaling_1518, scaling_1522, scaling_1523, scaling_1527, scaling_1538, scaling_1551, scaling_1559, scaling_1563, scaling_1569, scaling_1570, scaling_1571, scaling_1572, scaling_1573, scaling_1580, scaling_1582, scaling_1583, scaling_1597, scaling_1600, scaling_1601, scaling_1614, scaling_1616, scaling_1617, scaling_1624, scaling_1629, scaling_1635, scaling_1653, scaling_1659, scaling_1662, scaling_1702, scaling_1706, scaling_1711, scaling_1733, scaling_1778, scaling_1810, scaling_1811, scaling_1849, scaling_1851, scaling_1854, scaling_1865, scaling_1880, scaling_1901, scaling_1911, scaling_1925, scaling_2018, scaling_2044, scaling_2045, scaling_2059, scaling_2090

Last 10 lines of scaling_1510:
```
    reduction_indices=reduction_indices))
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 2326, in log
    "Log", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,631] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Log_grad/Reciprocal = Reciprocal[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum, ^gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/Select)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 5
![Cluster plot](error_class_plots/ouijaflow_memory_limit_5.png)

 * Number of instances: 4
 * Dataset ids: scaling_1514, scaling_1587, scaling_1612, scaling_1649

Last 10 lines of scaling_1514:
```
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py", line 1020, in _autopacking_conversion_function
    return _autopacking_helper(v, inferred_dtype, name or "packed")
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py", line 983, in _autopacking_helper
    return gen_array_ops._pack(elems_as_tensors, name=scope)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py", line 2839, in _pack
    "Pack", values=values, axis=axis, name=name)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[158,39811] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/stack_grad/unstack = Unpack[T=DT_FLOAT, axis=0, num=2, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/sub_grad/Reshape)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 6
![Cluster plot](error_class_plots/ouijaflow_memory_limit_6.png)

 * Number of instances: 20
 * Dataset ids: scaling_1515, scaling_1516, scaling_1543, scaling_1550, scaling_1552, scaling_1566, scaling_1652, scaling_1654, scaling_1660, scaling_1720, scaling_1742, scaling_1767, scaling_1775, scaling_1815, scaling_1834, scaling_1914, scaling_1977, scaling_2026, scaling_2034, scaling_2075

Last 10 lines of scaling_1515:
```
    name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[6310000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Exp, inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum/reduction_indices)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 7
![Cluster plot](error_class_plots/ouijaflow_memory_limit_7.png)

 * Number of instances: 20
 * Dataset ids: scaling_1531, scaling_1631, scaling_1691, scaling_1703, scaling_1710, scaling_1743, scaling_1758, scaling_1761, scaling_1785, scaling_1797, scaling_1819, scaling_1841, scaling_1850, scaling_1862, scaling_1894, scaling_1943, scaling_1953, scaling_1954, scaling_1996, scaling_2058

Last 10 lines of scaling_1531:
```
    return gen_math_ops.square(x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 4751, in square
    "Square", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10,630957] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/Square_1_grad/Mul = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/standardize_1/truediv, gradients/inference/sample/DropoutNormal_1/log_prob/Square_1_grad/Mul/y)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 8
![Cluster plot](error_class_plots/ouijaflow_memory_limit_8.png)

 * Number of instances: 12
 * Dataset ids: scaling_1535, scaling_1555, scaling_1588, scaling_1608, scaling_1622, scaling_1641, scaling_1667, scaling_1707, scaling_1725, scaling_1737, scaling_1933, scaling_2105

Last 10 lines of scaling_1535:
```
    "Log", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100,63096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Log = Log[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Sum)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 9
![Cluster plot](error_class_plots/ouijaflow_memory_limit_9.png)

 * Number of instances: 2
 * Dataset ids: scaling_1542, scaling_1554

Last 10 lines of scaling_1542:
```
    "IsFinite", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,6310,1000] and type bool on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/IsFinite = IsFinite[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/Max)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 10
![Cluster plot](error_class_plots/ouijaflow_memory_limit_10.png)

 * Number of instances: 23
 * Dataset ids: scaling_1581, scaling_1647, scaling_1651, scaling_1688, scaling_1749, scaling_1757, scaling_1763, scaling_1784, scaling_1799, scaling_1836, scaling_1840, scaling_1846, scaling_1872, scaling_1876, scaling_1902, scaling_1908, scaling_1929, scaling_1930, scaling_1955, scaling_1963, scaling_1974, scaling_1975, scaling_2104

Last 10 lines of scaling_1581:
```
    "Add", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15849,398] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/add_2 = Add[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/add, inference/sample/DropoutNormal_1/log_prob/sub)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 11
![Cluster plot](error_class_plots/ouijaflow_memory_limit_11.png)

 * Number of instances: 3
 * Dataset ids: scaling_1603, scaling_1713, scaling_1755

Last 10 lines of scaling_1603:
```
    return gen_math_ops._mul(x, y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 2789, in _mul
    "Mul", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[158489,40] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/mul_grad/mul_1 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/mul/x, gradients/inference/sample/DropoutNormal_1/log_prob/stack_grad/unstack:1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 12
![Cluster plot](error_class_plots/ouijaflow_memory_limit_12.png)

 * Number of instances: 21
 * Dataset ids: scaling_1606, scaling_1744, scaling_1766, scaling_1790, scaling_1823, scaling_1884, scaling_1886, scaling_1889, scaling_1988, scaling_2043, scaling_2073, scaling_2088, scaling_2099, scaling_2125, scaling_2144, scaling_2157, scaling_2159, scaling_2160, scaling_2169, scaling_2187, scaling_2188

Last 10 lines of scaling_1606:
```
    "Log", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[630957,10] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/Log = Log[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/Normal/scale)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 13
![Cluster plot](error_class_plots/ouijaflow_memory_limit_13.png)

 * Number of instances: 37
 * Dataset ids: scaling_1626, scaling_1634, scaling_1655, scaling_1700, scaling_1736, scaling_1752, scaling_1772, scaling_1861, scaling_1891, scaling_1931, scaling_1965, scaling_2001, scaling_2025, scaling_2033, scaling_2121, scaling_2124, scaling_2126, scaling_2127, scaling_2130, scaling_2131, scaling_2133, scaling_2143, scaling_2151, scaling_2158, scaling_2161, scaling_2167, scaling_2176, scaling_2189, scaling_2191, scaling_2192, scaling_2193, scaling_2202, scaling_2204, scaling_2207, scaling_2209, scaling_2223, scaling_2225

Last 10 lines of scaling_1626:
```
    return -0.5 * math_ops.square(self._z(x))
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py", line 232, in _z
    return (x - self.loc) / self.scale
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 934, in binary_op_wrapper
    return func(x, y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1030, in _truediv_python3
    return gen_math_ops._real_div(x, y, name=name)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10,1000000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/standardize/truediv_grad/Neg = Neg[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/standardize/sub)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 14
![Cluster plot](error_class_plots/ouijaflow_memory_limit_14.png)

 * Number of instances: 24
 * Dataset ids: scaling_1627, scaling_1666, scaling_1668, scaling_1698, scaling_1719, scaling_1805, scaling_1827, scaling_1918, scaling_1934, scaling_1941, scaling_1942, scaling_1976, scaling_1992, scaling_2000, scaling_2168, scaling_2170, scaling_2183, scaling_2184, scaling_2190, scaling_2206, scaling_2208, scaling_2216, scaling_2222, scaling_2224

Last 10 lines of scaling_1627:
```
    "Softplus", features=features, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25,398107] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/LogSigmoid/Softplus = Softplus[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/LogSigmoid/Neg)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 15
![Cluster plot](error_class_plots/ouijaflow_memory_limit_15.png)

 * Number of instances: 30
 * Dataset ids: scaling_1628, scaling_1781, scaling_1798, scaling_1802, scaling_1837, scaling_1845, scaling_1847, scaling_1898, scaling_1903, scaling_1947, scaling_1952, scaling_1986, scaling_2009, scaling_2012, scaling_2013, scaling_2022, scaling_2036, scaling_2050, scaling_2062, scaling_2077, scaling_2082, scaling_2083, scaling_2108, scaling_2109, scaling_2111, scaling_2139, scaling_2145, scaling_2166, scaling_2185, scaling_2199

Last 10 lines of scaling_1628:
```
    elem = copy(x, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 270, in copy
    new_op = copy(op, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 316, in copy
    op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[40,251189] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/mul_7 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/qmu0/sample/exp/forward/Exp, inference/sample/Sigmoid)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 16
![Cluster plot](error_class_plots/ouijaflow_memory_limit_16.png)

 * Number of instances: 3
 * Dataset ids: scaling_1632, scaling_1820, scaling_1937

Last 10 lines of scaling_1632:
```
    return func(x, y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 4819, in _sub
    "Sub", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[398,25119] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/sub_grad/Neg = Neg[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/DropoutNormal_1/log_prob/stack_grad/unstack:1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 17
![Cluster plot](error_class_plots/ouijaflow_memory_limit_17.png)

 * Number of instances: 21
 * Dataset ids: scaling_1640, scaling_1683, scaling_1768, scaling_1939, scaling_2028, scaling_2029, scaling_2049, scaling_2070, scaling_2079, scaling_2092, scaling_2102, scaling_2110, scaling_2112, scaling_2196, scaling_2232, scaling_2252, scaling_2296, scaling_2298, scaling_2301, scaling_2304, scaling_2317

Last 10 lines of scaling_1640:
```
    "Fill", dims=dims, value=value, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,15849,631] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/zeros_like = Fill[T=DT_FLOAT, index_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/zeros_like/shape_as_tensor, inference/sample/DropoutNormal_1/log_prob/ReduceLogSumExp/zeros_like/Const)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 18
![Cluster plot](error_class_plots/ouijaflow_memory_limit_18.png)

 * Number of instances: 12
 * Dataset ids: scaling_1644, scaling_1735, scaling_1853, scaling_1858, scaling_1877, scaling_1896, scaling_1907, scaling_1956, scaling_2117, scaling_2136, scaling_2150, scaling_2198

Last 10 lines of scaling_1644:
```
    "Sub", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[158489,63] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/standardize/sub = Sub[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](data/Variable/read, inference/sample/DropoutNormal_1/log_prob/Normal/loc)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 19
![Cluster plot](error_class_plots/ouijaflow_memory_limit_19.png)

 * Number of instances: 18
 * Dataset ids: scaling_1645, scaling_1686, scaling_1693, scaling_1828, scaling_1831, scaling_1838, scaling_1856, scaling_1881, scaling_1921, scaling_1924, scaling_1935, scaling_1946, scaling_1949, scaling_1950, scaling_1962, scaling_1966, scaling_1967, scaling_1990

Last 10 lines of scaling_1645:
```
    "Square", x=x, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[251189,40] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/Square = Square[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/standardize/truediv)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 20
![Cluster plot](error_class_plots/ouijaflow_memory_limit_20.png)

 * Number of instances: 62
 * Dataset ids: scaling_1648, scaling_1776, scaling_1818, scaling_1864, scaling_1868, scaling_1951, scaling_1959, scaling_1961, scaling_1985, scaling_2005, scaling_2039, scaling_2053, scaling_2054, scaling_2061, scaling_2063, scaling_2064, scaling_2065, scaling_2067, scaling_2093, scaling_2100, scaling_2197, scaling_2235, scaling_2236, scaling_2238, scaling_2239, scaling_2240, scaling_2241, scaling_2242, scaling_2243, scaling_2244, scaling_2256, scaling_2257, scaling_2258, scaling_2259, scaling_2260, scaling_2261, scaling_2262, scaling_2263, scaling_2264, scaling_2265, scaling_2277, scaling_2278, scaling_2279, scaling_2280, scaling_2281, scaling_2282, scaling_2283, scaling_2284, scaling_2285, scaling_2302, scaling_2303, scaling_2305, scaling_2306, scaling_2320, scaling_2321, scaling_2322, scaling_2323, scaling_2324, scaling_2325, scaling_2326, scaling_2327, scaling_2328

Last 10 lines of scaling_1648:
```
    elem = copy(x, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 270, in copy
    new_op = copy(op, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 316, in copy
    op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10,1000000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/stack, inference/sample/stack_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 21
![Cluster plot](error_class_plots/ouijaflow_memory_limit_21.png)

 * Number of instances: 17
 * Dataset ids: scaling_1658, scaling_1777, scaling_1788, scaling_1808, scaling_1991, scaling_2047, scaling_2055, scaling_2071, scaling_2086, scaling_2101, scaling_2113, scaling_2115, scaling_2149, scaling_2153, scaling_2200, scaling_2201, scaling_2213

Last 10 lines of scaling_1658:
```
    "Select", condition=condition, t=x, e=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2512,3981] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/Select = Select[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/Equal, gradients/mul_22_grad/Reshape_1, gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/zeros_like)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 22
![Cluster plot](error_class_plots/ouijaflow_memory_limit_22.png)

 * Number of instances: 8
 * Dataset ids: scaling_1675, scaling_1741, scaling_1773, scaling_1801, scaling_1807, scaling_1833, scaling_1899, scaling_2010

Last 10 lines of scaling_1675:
```
    return -0.5 * math_ops.square(self._z(x))
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py", line 232, in _z
    return (x - self.loc) / self.scale
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 934, in binary_op_wrapper
    return func(x, y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1030, in _truediv_python3
    return gen_math_ops._real_div(x, y, name=name)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[251,39811] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/standardize_1/truediv_grad/RealDiv = RealDiv[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/DropoutNormal_1/log_prob/Square_1_grad/Mul_1, inference/sample/DropoutNormal_1/log_prob/Normal_1/scale)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 23
![Cluster plot](error_class_plots/ouijaflow_memory_limit_23.png)

 * Number of instances: 21
 * Dataset ids: scaling_1677, scaling_1787, scaling_1826, scaling_1888, scaling_1910, scaling_1945, scaling_1957, scaling_1983, scaling_1984, scaling_2114, scaling_2119, scaling_2135, scaling_2141, scaling_2154, scaling_2155, scaling_2165, scaling_2171, scaling_2186, scaling_2203, scaling_2217, scaling_2221

Last 10 lines of scaling_1677:
```
    return func(x, y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 4819, in _sub
    "Sub", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[631,15849] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/sub_1_grad/Neg = Neg[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/Select_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 24
![Cluster plot](error_class_plots/ouijaflow_memory_limit_24.png)

 * Number of instances: 13
 * Dataset ids: scaling_1699, scaling_1701, scaling_1740, scaling_1771, scaling_1867, scaling_1869, scaling_1904, scaling_1926, scaling_1927, scaling_1971, scaling_1982, scaling_1989, scaling_1997

Last 10 lines of scaling_1699:
```
    "Add", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[631,15849] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/add = Add[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/Neg, inference/sample/DropoutNormal_1/log_prob/LogSigmoid)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 25
![Cluster plot](error_class_plots/ouijaflow_memory_limit_25.png)

 * Number of instances: 10
 * Dataset ids: scaling_1715, scaling_1762, scaling_1835, scaling_1883, scaling_1887, scaling_1979, scaling_2023, scaling_2152, scaling_2173, scaling_2218

Last 10 lines of scaling_1715:
```
    return gen_math_ops._mul(x, y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 2789, in _mul
    "Mul", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25,398107] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/mul_1_grad/mul_1 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/mul_1/x, gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/Select_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 26
![Cluster plot](error_class_plots/ouijaflow_memory_limit_26.png)

 * Number of instances: 9
 * Dataset ids: scaling_1716, scaling_1718, scaling_1866, scaling_1919, scaling_1932, scaling_2156, scaling_2172, scaling_2219, scaling_2220

Last 10 lines of scaling_1716:
```
    "RealDiv", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[40,251189] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/standardize/truediv = RealDiv[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/standardize/sub, inference/sample/DropoutNormal_1/log_prob/Normal/scale)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 27
![Cluster plot](error_class_plots/ouijaflow_memory_limit_27.png)

 * Number of instances: 13
 * Dataset ids: scaling_1717, scaling_1746, scaling_1964, scaling_1968, scaling_2021, scaling_2030, scaling_2066, scaling_2095, scaling_2118, scaling_2181, scaling_2215, scaling_2286, scaling_2307

Last 10 lines of scaling_1717:
```
    "Select", condition=condition, t=x, e=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[63,158489] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/Select_1 = Select[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/Equal, gradients/inference/sample/DropoutNormal_1/log_prob/Select_grad/zeros_like, gradients/mul_22_grad/Reshape_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 28
![Cluster plot](error_class_plots/ouijaflow_memory_limit_28.png)

 * Number of instances: 15
 * Dataset ids: scaling_1721, scaling_1800, scaling_1816, scaling_1843, scaling_1882, scaling_1923, scaling_1928, scaling_1940, scaling_1987, scaling_2046, scaling_2123, scaling_2129, scaling_2142, scaling_2182, scaling_2214

Last 10 lines of scaling_1721:
```
    elem = copy(x, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 270, in copy
    new_op = copy(op, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 316, in copy
    op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[631,15849] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/mul_8 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/strided_slice_1, inference/sample/mul_7)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 29
![Cluster plot](error_class_plots/ouijaflow_memory_limit_29.png)

 * Number of instances: 34
 * Dataset ids: scaling_1729, scaling_1754, scaling_1793, scaling_1860, scaling_1948, scaling_1995, scaling_2006, scaling_2007, scaling_2008, scaling_2011, scaling_2014, scaling_2015, scaling_2032, scaling_2037, scaling_2038, scaling_2042, scaling_2048, scaling_2052, scaling_2057, scaling_2068, scaling_2072, scaling_2081, scaling_2084, scaling_2091, scaling_2094, scaling_2097, scaling_2098, scaling_2233, scaling_2234, scaling_2254, scaling_2255, scaling_2275, scaling_2276, scaling_2299

Last 10 lines of scaling_1729:
```
    name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25119,398] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/Sum_12_grad/Tile = Tile[T=DT_FLOAT, Tmultiples=DT_INT32, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/Sum_12_grad/Reshape, gradients/Sum_12_grad/Tile/multiples)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 30
![Cluster plot](error_class_plots/ouijaflow_memory_limit_30.png)

 * Number of instances: 25
 * Dataset ids: scaling_1739, scaling_1745, scaling_1780, scaling_1813, scaling_1920, scaling_1944, scaling_1981, scaling_2004, scaling_2024, scaling_2031, scaling_2051, scaling_2060, scaling_2069, scaling_2076, scaling_2078, scaling_2080, scaling_2096, scaling_2164, scaling_2231, scaling_2253, scaling_2273, scaling_2274, scaling_2297, scaling_2300, scaling_2318

Last 10 lines of scaling_1739:
```
    "Fill", dims=dims, value=value, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[630957,16] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/zeros = Fill[T=DT_FLOAT, index_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/DropoutNormal_1/log_prob/zeros/shape_as_tensor, inference/sample/DropoutNormal_1/log_prob/zeros/Const)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 31
![Cluster plot](error_class_plots/ouijaflow_memory_limit_31.png)

 * Number of instances: 5
 * Dataset ids: scaling_1756, scaling_1759, scaling_1999, scaling_2003, scaling_2035

Last 10 lines of scaling_1756:
```
Input saved to /data/tmp//Rtmp2Ew0Mg/filef3d647a848c2/ti/input: 
	expression.csv
	params.json
Running /bin/singularity run --pwd /ti/workspace -B \
  '/data/tmp//Rtmp2Ew0Mg/filef3d647a848c2/ti:/ti,/data/tmp//Rtmp2Ew0Mg/filef3d6507122ec/tmp:/tmp2' \
  /group/irc/shared/dynverse/dynbenchmark/derived/singularity_images/dynverse/ti_ouijaflow.simg
   1/1000 [  0%]                                ETA: 4207s | Loss: 25327774.000terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
```

### ERROR CLUSTER MEMORY_LIMIT -- 32
![Cluster plot](error_class_plots/ouijaflow_memory_limit_32.png)

 * Number of instances: 2
 * Dataset ids: scaling_1782, scaling_1796

Last 10 lines of scaling_1782:
```
    "RealDiv", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[251189] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/qt0/sample/ExpShift/forward/truediv = RealDiv[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/qt0/sample/ExpShift/forward/add, inference/sample/qt0/sample/ExpShift/forward/add_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 33
![Cluster plot](error_class_plots/ouijaflow_memory_limit_33.png)

 * Number of instances: 3
 * Dataset ids: scaling_1786, scaling_1870, scaling_2016

Last 10 lines of scaling_1786:
```
    elem = copy(x, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 270, in copy
    new_op = copy(op, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 316, in copy
    op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1000,15849] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/mul_8_grad/mul = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/add_grad/Reshape_1, inference/sample/mul_7)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 34
![Cluster plot](error_class_plots/ouijaflow_memory_limit_34.png)

 * Number of instances: 2
 * Dataset ids: scaling_1915, scaling_2020

Last 10 lines of scaling_1915:
```
    elem = copy(x, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 270, in copy
    new_op = copy(op, dict_swap, scope, True, copy_q, False)
  File "/usr/local/lib/python3.6/site-packages/edward/util/random_variables.py", line 316, in copy
    op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[63,398107] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/mul_8_grad/mul_1 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](inference/sample/strided_slice_1, gradients/inference/sample/add_grad/Reshape_1)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 35
![Cluster plot](error_class_plots/ouijaflow_memory_limit_35.png)

 * Number of instances: 14
 * Dataset ids: scaling_1969, scaling_2107, scaling_2237, scaling_2245, scaling_2246, scaling_2266, scaling_2267, scaling_2287, scaling_2288, scaling_2308, scaling_2309, scaling_2319, scaling_2329, scaling_2330

Last 10 lines of scaling_1969:
```
    "Equal", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,2512] and type bool on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/DropoutNormal_1/log_prob/Equal = Equal[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](data/Variable/read, inference/sample/DropoutNormal_1/log_prob/zeros)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 36
![Cluster plot](error_class_plots/ouijaflow_memory_limit_36.png)

 * Number of instances: 1
 * Dataset ids: scaling_2041

Last 10 lines of scaling_2041:
```
    "Sub", x=x, y=y, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[630957] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: inference/sample/qt0/log_prob/ExpShift_1/inverse_log_det_jacobian/sub_1 = Sub[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](ones_16, inference/sample/qt0/sample/ExpShift/forward/truediv)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 37
![Cluster plot](error_class_plots/ouijaflow_memory_limit_37.png)

 * Number of instances: 1
 * Dataset ids: scaling_2056

Last 10 lines of scaling_2056:
```
    return self._call_log_prob(value, name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py", line 698, in _call_log_prob
    return self._log_prob(value, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py", line 189, in _log_prob
    return self._log_unnormalized_prob(x) - self._log_normalization()
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py", line 207, in _log_unnormalized_prob
    return -0.5 * math_ops.square(self._z(x))
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[630957] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/NormalWithSoftplusScale_1/log_prob/standardize/sub_grad/Neg = Neg[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/NormalWithSoftplusScale_1/log_prob/standardize/truediv_grad/Reshape)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 38
![Cluster plot](error_class_plots/ouijaflow_memory_limit_38.png)

 * Number of instances: 1
 * Dataset ids: scaling_2085

Last 10 lines of scaling_2085:
```
    lp_amp = -prob_dropout_logit + tf.log_sigmoid(prob_dropout_logit)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 2301, in log_sigmoid
    return gen_math_ops._neg(gen_nn_ops.softplus(-x), name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 4607, in softplus
    "Softplus", features=features, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[630957,63] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: gradients/inference/sample/DropoutNormal_1/log_prob/LogSigmoid/Softplus_grad/SoftplusGrad = SoftplusGrad[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](gradients/inference/sample/DropoutNormal_1/log_prob/LogSigmoid_grad/Neg, inference/sample/DropoutNormal_1/log_prob/LogSigmoid/Neg)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 39
![Cluster plot](error_class_plots/ouijaflow_memory_limit_39.png)

 * Number of instances: 4
 * Dataset ids: scaling_2146, scaling_2229, scaling_2271, scaling_2292

Last 10 lines of scaling_2146:
```
    use_locking=use_locking, name=name)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3271, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100,630957] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[Node: data/Variable/Assign = Assign[T=DT_FLOAT, _class=["loc:@data/Variable"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/device:CPU:0"](data/Variable, _arg_data/Placeholder_0_0)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```

### ERROR CLUSTER MEMORY_LIMIT -- 40
![Cluster plot](error_class_plots/ouijaflow_memory_limit_40.png)

 * Number of instances: 8
 * Dataset ids: scaling_2147, scaling_2163, scaling_2178, scaling_2179, scaling_2194, scaling_2195, scaling_2210, scaling_2211

Last 10 lines of scaling_2147:
```
Input saved to /data/tmp//RtmpVv67VH/file1111778b80646/ti/input: 
	expression.csv
	params.json
Running /bin/singularity run --pwd /ti/workspace -B \
  '/data/tmp//RtmpVv67VH/file1111778b80646/ti:/ti,/data/tmp//RtmpVv67VH/file111173375d6b0/tmp:/tmp2' \
  /group/irc/shared/dynverse/dynbenchmark/derived/singularity_images/dynverse/ti_ouijaflow.simg
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
```

### ERROR CLUSTER MEMORY_LIMIT -- 41
![Cluster plot](error_class_plots/ouijaflow_memory_limit_41.png)

 * Number of instances: 1
 * Dataset ids: scaling_2162

Last 10 lines of scaling_2162:
```
2018-10-16 20:35:51.466047: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957,1] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.469949: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470054: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470093: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470139: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470175: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957,1] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470214: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957,1] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470270: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470301: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957] and type float on /device:CPU:0 by allocator cpu
2018-10-16 20:35:51.470343: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at constant_op.cc:169 : Resource exhausted: OOM when allocating tensor with shape[630957,1] and type float on /device:CPU:0 by allocator cpu
```

### ERROR CLUSTER MEMORY_LIMIT -- 42
![Cluster plot](error_class_plots/ouijaflow_memory_limit_42.png)

 * Number of instances: 7
 * Dataset ids: scaling_2226, scaling_2228, scaling_2247, scaling_2270, scaling_2289, scaling_2290, scaling_2291

Last 10 lines of scaling_2226:
```
    data = parser.read(nrows)
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1036, in read
    ret = self._engine.read(nrows)
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1848, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 876, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 891, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 968, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 1107, in pandas._libs.parsers.TextReader._convert_column_data
MemoryError
```

### ERROR CLUSTER MEMORY_LIMIT -- 43
![Cluster plot](error_class_plots/ouijaflow_memory_limit_43.png)

 * Number of instances: 2
 * Dataset ids: scaling_2268, scaling_2310

Last 10 lines of scaling_2268:
```
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 446, in _read
    data = parser.read(nrows)
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1036, in read
    ret = self._engine.read(nrows)
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1848, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 876, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 891, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 975, in pandas._libs.parsers.TextReader._read_rows
MemoryError
```

### ERROR CLUSTER MEMORY_LIMIT -- 44
![Cluster plot](error_class_plots/ouijaflow_memory_limit_44.png)

 * Number of instances: 1
 * Dataset ids: scaling_2312

Last 10 lines of scaling_2312:
```
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1036, in read
    ret = self._engine.read(nrows)
  File "/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py", line 1848, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 876, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 891, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 968, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 1060, in pandas._libs.parsers.TextReader._convert_column_data
  File "pandas/_libs/parsers.pyx", line 1308, in pandas._libs.parsers.TextReader._get_na_list
MemoryError
```


